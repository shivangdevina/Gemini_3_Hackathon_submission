# -*- coding: utf-8 -*-
"""ques_&_discussion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14XhaaGjoG1QKYkJ5Gjld0DZH5nhFMZjy
"""



from typing import TypedDict, List
import json
import re
import os

from typing import TypedDict, List, Dict
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END

import os
from dotenv import load_dotenv, find_dotenv

# Make sure this is set in environment
_ = load_dotenv(find_dotenv())
api_key = os.getenv("GOOGLE_API_KEY")
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    google_api_key=api_key
)

def safe_json_parse(text: str):
    # Try object first
    obj_match = re.search(r"\{.*\}", text, re.DOTALL)
    if obj_match:
        return json.loads(obj_match.group())

    # Fallback: array-only JSON
    arr_match = re.search(r"\[.*\]", text, re.DOTALL)
    if arr_match:
        return json.loads(arr_match.group())

    raise ValueError(text)

def generate_basic_ideation_questions(problem_statement: str, team_context: str):
    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
You are an expert product strategist facilitating a structured brainstorming session.

Use the team context only for feasibility awareness.
Do NOT ask questions about the team.

Return ONLY valid JSON in this format:

{{
  "basic_ideation_questions": [
    "question 1",
    "question 2",
    "...",
    "question 8"
  ]
}}
"""
        ),
        (
            "human",
            """
Problem Statement:
{ps}

Team & Teammate Context:
{team}
"""
        )
    ])

    response = llm.invoke(
        prompt.format_messages(ps=problem_statement, team=team_context)
    )
    return response.content

def generate_architecture_questions(problem_statement: str, document: str):
    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
You are a senior system architect guiding a technical brainstorming session.

You are given team and teammate context to understand technical comfort level and constraints.
Use it only to shape realism, not to ask team-specific questions.

Your task is to generate a structured sequence of questions that moves from idea to system design.

Flow:
- Desired user outcome
- Major system components
- Data and AI usage (only where useful)
- Constraints, feasibility, and MVP scope

Guidelines:
- Start with outcomes, not tools
- Keep language very simple
- Avoid over-engineering
- End with feasibility and risk

Output format:
Return ONLY valid JSON in this format:

{{
  "architecture_questions": [
    "question 1",
    "question 2",
    "...",
    "question 8"
  ]
}}
"""
        ),
        (
            "human",
            """
Problem Statement:
{ps}

Team & Teammate Context:
{team}
"""
        )
    ])

    response = llm.invoke(
        prompt.format_messages(ps=problem_statement, team=document)
    )
    return response.content

def generate_final_ps_questions(problem_statement: str, document: str):
    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
You are facilitating a deep, final-stage problem analysis.

You are given team context to assess long-term feasibility and defensibility.
Do NOT ask about the team directly.

Your task is to generate a progression of questions that deeply interrogate the problem.

Flow:
- Clarify the problem definition
- Examine existing solutions
- Identify root causes
- Evaluate tech intervention
- Assess adoption and long-term relevance

Guidelines:
- Tighten problem definition early
- Avoid feature-level thinking
- Keep questions very simple

Output format:
Return ONLY valid JSON in this format:

{{
  "final_ps_questions": [
    "question 1",
    "question 2",
    "...",
    "question 8"
  ]
}}
"""
        ),
        (
            "human",
            """
Problem Statement:
{ps}

Team & Teammate Context:
{team}
"""
        )
    ])

    response = llm.invoke(
        prompt.format_messages(ps=problem_statement, team=document)
    )
    return response.content

ps = "Design a low-cost digital solution to help rural communities access essential services despite limited internet connectivity."

team_doc = """
"""



import json

def generate_combined_questions(problem_statement: str, team_context: str):
    all_questions = []

    # Generate basic ideation questions
    basic_ideation_raw = generate_basic_ideation_questions(problem_statement, team_context)
    basic_ideation_dict = safe_json_parse(basic_ideation_raw)
    for q in basic_ideation_dict.get("basic_ideation_questions", []):
        all_questions.append({"answer": "", "question": q})

    # Generate architecture questions
    architecture_raw = generate_architecture_questions(problem_statement, team_context)
    architecture_dict = safe_json_parse(architecture_raw)
    for q in architecture_dict.get("architecture_questions", []):
        all_questions.append({"answer": "", "question": q})

    # Generate final PS questions
    final_ps_raw = generate_final_ps_questions(problem_statement, team_context)
    final_ps_dict = safe_json_parse(final_ps_raw)
    for q in final_ps_dict.get("final_ps_questions", []):
        all_questions.append({"answer": "", "question": q})

    return all_questions

# Call the new function with the existing problem statement and team context
