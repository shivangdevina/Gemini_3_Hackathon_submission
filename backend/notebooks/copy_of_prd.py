# -*- coding: utf-8 -*-
"""Copy of PRD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-5xNacrhMJetTKzVAlKkB6IoBV0fofIX
"""

# pip install langchain_google_genai

from typing import TypedDict, List,Dict
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from typing import TypedDict, Optional
from typing import TypedDict
from langchain_core.messages import HumanMessage


from langchain_google_genai import ChatGoogleGenerativeAI

from typing import TypedDict, Optional
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage

import os
os.environ["GOOGLE_API_KEY"] = "AIzaSyCQPB1lVL2hOwvEKO_v2Ta_D8tuWs2zllc"

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0
)

class QAPair(TypedDict):
    question: str
    answer: str

class PRDState(TypedDict):
    problem_statement: str
    pitch: str
    qa_pairs: List[QAPair]  # Dictionary format as requested
    prd: Optional[str]
    evaluation: Optional[str]
    refined_prd: Optional[str]


QUESTION_GENERATION_PROMPT = """
You are a senior technical product strategist.

Given the following product pitch and problem statement, generate a structured list of questions
that progress from general to highly specific technical depth.

Problem Statement:
{ps}

Pitch:
{pitch}

Instructions:
- Start with high-level intent and value questions
- Gradually move to system architecture questions
- End with deep technical, data, model, scalability, and risk questions
- Questions should help clarify and stress-test the pitch
- Output as a numbered list, grouped by levels

Levels:
Level 1 – Vision & Intent
Level 2 – System & Architecture
Level 3 – Data & Models
Level 4 – Infrastructure & Scalability
Level 5 – Risks, Constraints, and Edge Cases
"""


PRD_GENERATION_PROMPT = """
You are a Principal Product Manager with a strong systems architecture and AI background.

Generate a highly detailed, technically rigorous Product Requirement Document (PRD) using:

Problem Statement:
{ps}

Questions_answer_pair:
{qa_pairs}

Pitch (Architecture + Technical + Vision):
{pitch}

Instructions:
- This is a TECHNICAL PRD intended for architects, AI engineers, and senior stakeholders.
- Focus on WHAT the system must support technically, not step-by-step coding.
- Be explicit about system boundaries, data flows, models, infra expectations, and constraints.
- Avoid generic product language. Prefer precise, engineering-aligned requirements.
- Assume this PRD will be used for an academic + production-grade system.

PRD Structure:

1. Product Overview
   - Technical problem definition
   - System-level intent
   - Why existing approaches fail technically

2. Objectives & Success Criteria
   - Quantitative technical KPIs
   - Latency, accuracy, robustness, explainability targets

3. User Personas & Use Cases
   - Personas mapped to system interactions
   - Technical expectations per persona

4. System Architecture Overview
   - High-level components (logical, not code)
   - Data flow between components
   - External system dependencies
   - AI/ML components if applicable

5. Functional Requirements
   - Clearly numbered
   - Each requirement must describe:
     • input
     • processing expectation
     • output
     • constraints
   - Cover:
     • data ingestion
     • processing
     • decision-making
     • feedback loops
     • monitoring

6. Non-Functional Requirements
   - Performance (latency, throughput)
   - Scalability (horizontal/vertical assumptions)
   - Reliability & fault tolerance
   - Security & privacy
   - Explainability & auditability
   - Maintainability

7. Data & Model Requirements (if applicable)
   - Data sources and characteristics
   - Data quality expectations
   - Model behavior expectations (not training steps)
   - Bias, drift, and validation constraints

8. Infrastructure & Deployment Assumptions
   - Cloud/on-prem expectations
   - Runtime constraints
   - Resource assumptions
   - Cost sensitivity

9. Scope & Boundaries
   - Explicit in-scope vs out-of-scope
   - Hard system limits

10. Assumptions & Constraints
    - Technical
    - Organizational
    - Regulatory

11. Risks & Open Questions
    - Technical risks
    - Research risks
    - Scalability risks
    - Data risks
"""


PRD_EVALUATION_PROMPT = """
You are a Technical Product Review Board consisting of:
- Principal Product Manager
- Senior System Architect
- AI Research Lead
- Infrastructure Engineer

Evaluate the following PRD:

{prd}

Evaluate on:
1. Technical depth and specificity
2. Architectural clarity
3. Data and model rigor
4. Scalability and performance realism
5. Risk identification quality
6. Internal consistency
7. Research and production readiness

Output:
- Overall Technical Score (1–10)
- Strengths (technical)
- Weaknesses (technical)
- Missing Technical Sections
- High-Risk Technical Assumptions
- Concrete Recommendations
"""



PRD_IMPROVEMENT_PROMPT = """
You are a senior technical product consultant and systems architect.

Original PRD:
{prd}

Evaluation Report:
{evaluation}

TASK:
Rewrite and significantly EXPAND the PRD to be highly detailed, technically rigorous, and architecturally precise.

CRITICAL INSTRUCTIONS:
- Output MUST be in MARKDOWN format (a proper one showing bigger font for topic ,medium for sub topic ,and smaller for content , with proper bullet points and headers and good spacing , all this in markdown format)
- DO NOT include document metadata (no version, date, author)
- DO NOT summarize — EXPAND every section
- Assume the audience is:
  • AI engineers
  • System architects
  • Research reviewers
  • Senior technical stakeholders
- This PRD should be suitable for:
  • academic review
  • system design handoff
  • production planning

DEPTH REQUIREMENTS (VERY IMPORTANT):
- Each section should contain multiple paragraphs
- Functional requirements must be granular and explicit
- Architecture must describe component responsibilities and boundaries
- Data and model sections must include constraints, expectations, and validation logic
- Non-functional requirements must include measurable targets
- Risks must be concrete, technical, and realistic

STRUCTURE (MANDATORY):

## 1. Product Overview
- Detailed technical problem definition
- System-level intent
- Why existing technical approaches fail

## 2. Objectives & Success Criteria
- Clearly defined technical objectives
- Quantitative KPIs
- Latency, accuracy, robustness, explainability targets

## 3. User Personas & Use Cases
- Multiple personas
- Detailed interaction flows
- Technical expectations per persona

## 4. System Architecture Overview
- High-level logical architecture
- Core components and responsibilities
- Data flow across the system
- External dependencies
- AI/ML subsystem boundaries

## 5. Functional Requirements
- Numbered requirements (FR-1, FR-2, ...)
- For each requirement specify:
  - Inputs
  - Processing logic (conceptual)
  - Outputs
  - Constraints
- Cover ingestion, analysis, inference, feedback, monitoring

## 6. Non-Functional Requirements
- Performance (latency, throughput)
- Scalability assumptions
- Reliability and fault tolerance
- Security and privacy
- Explainability and auditability
- Maintainability and extensibility

## 7. Data & Model Requirements
- Data sources and modalities
- Data quality expectations
- Model behavior expectations
- Validation, drift detection, and bias constraints
- Explainability requirements

## 8. Infrastructure & Deployment Assumptions
- Runtime environment assumptions
- Resource constraints
- Cost sensitivity
- Deployment and operational considerations

## 9. Scope & Boundaries
- Explicit in-scope items
- Explicit out-of-scope items
- Hard system limits

## 10. Assumptions & Constraints
- Technical assumptions
- Organizational constraints
- Regulatory or ethical constraints

## 11. Risks & Open Questions
- Technical risks
- Research risks
- Data risks
- Scalability risks
- Open design questions

IMPORTANT:
- Write with depth, precision, and clarity
- This should read like a real, serious technical PRD
"""



def generate_questions(state: PRDState):
    prompt = QUESTION_GENERATION_PROMPT.format(
        ps=state["problem_statement"],
        pitch=state["pitch"]
    )
    response = llm.invoke(prompt)
    return {"questions": response.content}


def generate_prd(state: PRDState):

    qa_formatted = ""
    for pair in state.get("qa_pairs", []):
        qa_formatted += f"Q: {pair['question']}\nA: {pair['answer']}\n\n"

    prompt = PRD_GENERATION_PROMPT.format(
        ps=state["problem_statement"],
        qa_pairs=qa_formatted,
        pitch=state["pitch"]
    )

    response = llm.invoke(prompt)
    return {"prd": response.content}


def evaluate_prd(state: PRDState):
    prompt = PRD_EVALUATION_PROMPT.format(
        prd=state["prd"]
    )

    response = llm.invoke(prompt)
    return {"evaluation": response.content}


def improve_prd(state: PRDState):
    prompt = PRD_IMPROVEMENT_PROMPT.format(
        prd=state["prd"],
        evaluation=state["evaluation"]
    )

    response = llm.invoke(prompt)
    return {"refined_prd": response.content}


builder = StateGraph(PRDState)


builder.add_node("generate_prd", generate_prd)
builder.add_node("evaluate_prd", evaluate_prd)
builder.add_node("improve_prd", improve_prd)

builder.set_entry_point("generate_prd")


builder.add_edge("generate_prd", "evaluate_prd")
builder.add_edge("evaluate_prd", "improve_prd")
builder.add_edge("improve_prd", END)

graph = builder.compile()


input_state = {
    "problem_statement": """Current hiring processes for technical and knowledge-based roles rely heavily on resumes, self-reported skills, and short interviews.
These methods fail to objectively evaluate a candidate’s cognitive load, stress response, and behavioral consistency under real-time questioning.

As a result:
- Interview outcomes are highly subjective and interviewer-dependent
- Candidates can game the process through rehearsed answers
- Organizations lack measurable signals for decision confidence, stress tolerance, and engagement
- There is no structured, explainable way to augment human interviews with physiological or behavioral signals

A system is needed to augment traditional interviews with interpretable, real-time analytical signals that improve fairness, consistency, and decision quality without replacing human judgment.
""",


    "pitch": """The proposed system is an AI-assisted interview intelligence platform that augments live or recorded interviews with real-time cognitive and behavioral signal analysis.

At a system level, the platform ingests multimodal interview data, including:
- Video streams of the candidate
- Optional thermal or physiological signal inputs
- Audio transcripts and speech features
- Interview context metadata (question type, difficulty, duration)

The system processes these inputs through modular analysis components:
- Signal preprocessing and normalization layers
- Feature extraction modules for facial dynamics, speech patterns, and temporal response behavior
- AI models that estimate stress indicators, engagement consistency, and cognitive load trends over time

Rather than producing a single opaque score, the platform generates:
- Time-aligned analytical indicators
- Confidence intervals and trend-based insights
- Explainable summaries tied to observable signals

Architecturally, the system is designed as a decoupled pipeline with clear boundaries between data ingestion, analysis, inference, and reporting layers.
This allows individual models or signal sources to evolve independently.

The long-term vision is to create a research-grade, explainable interview intelligence layer that integrates with existing ATS platforms, supports academic validation, and enables organizations to make higher-quality hiring decisions while maintaining transparency and ethical safeguards.
""",
    "qa_pairs": [
        {
            "question": "How will the system handle data privacy for video streams?",
            "answer": "All video processing is done via an ephemeral worker. Raw video is deleted post-inference; only anonymized metadata features are stored."
        },
        {
            "question": "What are the latency requirements for real-time analysis?",
            "answer": "The system must maintain sub-500ms latency for stress-indicator overlays during a live stream."
        }
    ]
}


# result = graph.invoke(input_state)

# print(result["refined_prd"])

def run_prd_agent(problem: str, pitch: str, qa_data: List[Dict[str, str]]):
    """
    Wrapper function for backend integration.
    Args:
        problem: The problem statement string.
        pitch: The product pitch string.
        qa_data: A list of dicts: [{"question": "...", "answer": "..."}]
    Returns:
        The final refined PRD markdown.
    """
    try:
        # Construct the initial state
        initial_state = {
            "problem_statement": problem,
            "pitch": pitch,
            "qa_pairs": qa_data
        }

        # Invoke the compiled graph
        result = graph.invoke(initial_state)

        # Return the final output key
        return result.get("refined_prd", "Error: PRD generation failed.")

    except Exception as e:
        return f"System Error: {str(e)}"

# Example Backend Usage:
#

problem_statement= """Current hiring processes for technical and knowledge-based roles rely heavily on resumes, self-reported skills, and short interviews.
These methods fail to objectively evaluate a candidate’s cognitive load, stress response, and behavioral consistency under real-time questioning.

As a result:
- Interview outcomes are highly subjective and interviewer-dependent
- Candidates can game the process through rehearsed answers
- Organizations lack measurable signals for decision confidence, stress tolerance, and engagement
- There is no structured, explainable way to augment human interviews with physiological or behavioral signals

A system is needed to augment traditional interviews with interpretable, real-time analytical signals that improve fairness, consistency, and decision quality without replacing human judgment.
"""
pitch=  """The proposed system is an AI-assisted interview intelligence platform that augments live or recorded interviews with real-time cognitive and behavioral signal analysis.

At a system level, the platform ingests multimodal interview data, including:
- Video streams of the candidate
- Optional thermal or physiological signal inputs
- Audio transcripts and speech features
- Interview context metadata (question type, difficulty, duration)

The system processes these inputs through modular analysis components:
- Signal preprocessing and normalization layers
- Feature extraction modules for facial dynamics, speech patterns, and temporal response behavior
- AI models that estimate stress indicators, engagement consistency, and cognitive load trends over time

Rather than producing a single opaque score, the platform generates:
- Time-aligned analytical indicators
- Confidence intervals and trend-based insights
- Explainable summaries tied to observable signals

Architecturally, the system is designed as a decoupled pipeline with clear boundaries between data ingestion, analysis, inference, and reporting layers.
This allows individual models or signal sources to evolve independently.

The long-term vision is to create a research-grade, explainable interview intelligence layer that integrates with existing ATS platforms, supports academic validation, and enables organizations to make higher-quality hiring decisions while maintaining transparency and ethical safeguards.
"""
qa_pairs= [
        {
            "question": "How will the system handle data privacy for video streams?",
            "answer": "All video processing is done via an ephemeral worker. Raw video is deleted post-inference; only anonymized metadata features are stored."
        },
        {
            "question": "What are the latency requirements for real-time analysis?",
            "answer": "The system must maintain sub-500ms latency for stress-indicator overlays during a live stream."
        }
    ]

# final_document = run_prd_agent(problem_statement, pitch, qa_pairs)

# print(final_document)

